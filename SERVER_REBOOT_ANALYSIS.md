# サーバー再起動の頻度と原因分析

## 🔍 サーバー再起動は頻発するのか？

**結論：通常、VPSサーバーは頻繁に再起動することはありません。**

しかし、以下の理由で再起動することがあります：

---

## 📊 サーバー再起動が発生する主な理由

### 1. 手動再起動（最も可能性が高い）

**原因：**
- VPSパネルからの手動再起動
- メンテナンス作業
- 設定変更後の再起動

**頻度：**
- 不定期（必要に応じて）

**確認方法：**
```bash
last reboot
uptime
```

---

### 2. システムアップデート後の自動再起動

**原因：**
- Ubuntuのセキュリティアップデート
- カーネルアップデート
- 重要なシステムパッケージのアップデート

**頻度：**
- 月に1〜2回程度（セキュリティアップデート時）
- 設定によっては自動再起動しない場合もある

**確認方法：**
```bash
# アップデート履歴
grep -i "upgrade\|install" /var/log/apt/history.log | tail -20

# 再起動履歴
last reboot
```

---

### 3. システムクラッシュ

**原因：**
- カーネルパニック
- ハードウェアエラー
- システムリソース不足によるクラッシュ

**頻度：**
- まれ（通常は発生しない）

**確認方法：**
```bash
dmesg | grep -i "panic\|crash\|error"
journalctl -k | grep -i "panic\|crash"
```

---

### 4. VPSプロバイダー側のメンテナンス

**原因：**
- XServer VPSのメンテナンス作業
- ハードウェアメンテナンス
- データセンターのメンテナンス

**頻度：**
- 数ヶ月に1回程度（事前通知あり）

**確認方法：**
- XServer VPSのメンテナンス通知を確認
- メール通知を確認

---

### 5. リソース不足による強制再起動

**原因：**
- メモリ不足
- ディスク容量不足
- CPU使用率が高い

**頻度：**
- まれ（適切に設定されていれば発生しない）

**確認方法：**
```bash
free -h
df -h
dmesg | grep -i "out of memory"
```

---

## 🔍 実際の再起動頻度を確認する方法

### 方法1: サーバーの稼働時間を確認

```bash
ssh pharmacy@yaku-navi.com
uptime
```

**出力例：**
```
 07:30:00 up 15 days,  2:30,  1 user,  load average: 0.50, 0.60, 0.70
```

- `up 15 days` → 15日間連続稼働（再起動していない）

### 方法2: 再起動履歴を確認

```bash
ssh pharmacy@yaku-navi.com
last reboot
```

**出力例：**
```
reboot   system boot  6.14.0-37-generi Mon Jan 13 02:05   still running
reboot   system boot  6.14.0-37-generi Mon Jan  6 10:30 - 02:05  (6+15:35)
reboot   system boot  6.14.0-37-generi Mon Dec 30 14:20 - 10:30  (6+20:10)
```

- 再起動の日時と頻度が確認できる

### 方法3: システムログで再起動を確認

```bash
ssh pharmacy@yaku-navi.com
journalctl --list-boots
```

**出力例：**
```
-1 abc123... Mon 2026-01-13 02:05:00 JST—Mon 2026-01-25 07:30:00 JST
-2 def456... Mon 2026-01-06 10:30:00 JST—Mon 2026-01-13 02:05:00 JST
-3 ghi789... Mon 2025-12-30 14:20:00 JST—Mon 2026-01-06 10:30:00 JST
```

---

## 📈 通常の再起動頻度（参考）

| 再起動理由 | 頻度 | 備考 |
|-----------|------|------|
| 手動再起動 | 不定期 | 必要に応じて |
| システムアップデート | 月1〜2回 | セキュリティアップデート時 |
| VPSメンテナンス | 数ヶ月に1回 | 事前通知あり |
| システムクラッシュ | まれ | 通常は発生しない |
| リソース不足 | まれ | 適切に設定されていれば発生しない |

**一般的なVPSサーバー：**
- 月に1〜2回程度の再起動が正常
- 週に1回以上再起動する場合は異常

---

## 🎯 PM2プロセスが停止する本当の原因

サーバー再起動が頻発していない場合、PM2プロセスが停止する他の原因を調査する必要があります：

### 1. PM2デーモンのクラッシュ

**確認方法：**
```bash
# PM2デーモンのログを確認
journalctl -u pm2-pharmacy -n 100

# システムログでPM2関連のエラーを確認
dmesg | grep -i pm2
journalctl | grep -i pm2
```

### 2. メモリ不足による強制終了

**確認方法：**
```bash
# メモリ使用状況
free -h

# OOM Killerの記録
dmesg | grep -i "out of memory"
journalctl -k | grep -i "out of memory"
```

### 3. アプリケーションのクラッシュによる連鎖反応

**確認方法：**
```bash
# PM2のログを確認
pm2 logs --lines 100

# エラーパターンを確認
pm2 logs | grep -i "error\|crash\|exit"
```

### 4. ログファイルの肥大化

**確認方法：**
```bash
# ログファイルのサイズを確認
du -sh ~/.pm2/logs/*
du -sh ~/pharmacy-platform/logs/*

# ディスク使用状況
df -h
```

---

## ✅ 推奨される調査手順

### ステップ1: サーバーの再起動頻度を確認

```bash
ssh pharmacy@yaku-navi.com

# 稼働時間を確認
uptime

# 再起動履歴を確認
last reboot | head -10

# システムログで再起動を確認
journalctl --list-boots | head -10
```

### ステップ2: PM2プロセスが停止した時刻を特定

```bash
# PM2のログを確認
pm2 logs --lines 200 | grep -E "stopped|exit|crash"

# システムログでPM2関連のエラーを確認
journalctl | grep -i pm2 | tail -50
```

### ステップ3: システムリソースを確認

```bash
# メモリ使用状況
free -h

# ディスク使用状況
df -h

# OOM Killerの記録
dmesg | grep -i "out of memory"
```

### ステップ4: パターンを分析

- 再起動と同時に停止している → サーバー再起動が原因
- 再起動なしで停止している → PM2デーモンのクラッシュが原因
- 定期的に停止している → リソース不足やログ肥大化が原因

---

## 🎯 結論

**サーバー再起動は通常頻発しません。**

- 月に1〜2回程度が正常
- 週に1回以上再起動する場合は異常

**PM2プロセスが停止する主な原因：**

1. **サーバー再起動**（再起動が発生した場合）
   - PM2自動起動設定が未実行
   - 再起動後にPM2デーモンが起動しない

2. **PM2デーモンのクラッシュ**（再起動なしで停止）
   - システムリソース不足
   - PM2のバグ
   - メモリリーク

3. **その他**
   - ログファイルの肥大化
   - 権限問題
   - システムの自動クリーンアップ

---

## 📝 次のステップ

1. **サーバーの再起動頻度を確認**
   - `uptime`で稼働時間を確認
   - `last reboot`で再起動履歴を確認

2. **PM2プロセスが停止した時刻を特定**
   - PM2のログを確認
   - システムログを確認

3. **原因に応じた対策を実施**
   - 再起動が原因 → PM2自動起動設定
   - クラッシュが原因 → リソース確認・改善
   - その他 → 個別に対応

---

**最終更新**: 2026年1月25日

